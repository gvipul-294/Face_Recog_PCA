{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import  matplotlib.image as mpimg\n",
    "\n",
    "from scipy import misc\n",
    "\n",
    "import argparse\n",
    "\n",
    "from PIL import Image \n",
    "\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "#k is the training size\n",
    "k = int(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/shivam/Downloads/Face_Recog_PCA-master/dataset_ORL/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2vector(filename):\n",
    "\n",
    "    imgVector = np.array(Image.open(filename)).flatten()\n",
    "    return imgVector.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((160, 10304), (160,), (240, 10304), (240,))\n"
     ]
    }
   ],
   "source": [
    "train_X = []\n",
    "train_Y = []\n",
    "test_X = []\n",
    "test_Y  = []\n",
    "\n",
    "for i in range(1,41):\n",
    "    for j in range(1,k+1):\n",
    "        image_add = path+\"s\"+str(i)+\"/\"+str(j)+\".pgm\"\n",
    "        img = img2vector(image_add)\n",
    "        train_X.append(img)\n",
    "        train_Y.append(i)\n",
    "        \n",
    "    for j in range(k+1,11):\n",
    "        image_add = path+\"s\"+str(i)+\"/\"+str(j)+\".pgm\"\n",
    "        img = img2vector(image_add)\n",
    "        test_X.append(img)\n",
    "        test_Y.append(i)\n",
    "\n",
    "X_train = np.array(train_X)\n",
    "Y_train = np.array(train_Y)\n",
    "X_test = np.array(test_X)\n",
    "Y_test = np.array(test_Y)\n",
    "\n",
    "print (X_train.shape,Y_train.shape,X_test.shape,Y_test.shape)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10304)\n",
      "(160, 10304)\n"
     ]
    }
   ],
   "source": [
    "#normalize according to paper\n",
    "\n",
    "mean = X_train.mean(axis = 0).reshape(1,10304)\n",
    "\n",
    "print (mean.shape)\n",
    "\n",
    "X_train -= mean\n",
    "X_test -= mean\n",
    "\n",
    "print (X_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute covariance matrix\n",
    "cov_train = np.dot(X_train.T,X_train)\n",
    "cov_test = np.dot(X_test.T,X_test)\n",
    "cov_train /= X_train.shape[0]\n",
    "cov_test /= X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#singular value decomposition for computing U : eigen vectors s : eigen values\n",
    "U_train, s_train, V_train = np.linalg.svd(cov_train, full_matrices = True)\n",
    "print (\" computed eigen vectors and values of shape {}\".format(U_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_test, s_test, V_test = np.linalg.svd(cov_test, full_matrices = True)\n",
    "print (\" computed eigen vectors and values of shape {}\".format(U_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# approx retain variance\n",
    "retain_variance = 0.85\n",
    "#sum of all eigen values\n",
    "eigen_value_sum = np.sum(s_train)\n",
    "var_eigen = np.array([(np.sum(s_train[: i + 1]) / eigen_value_sum) * 100.0 for i in range(s_train.shape[0])])\n",
    "\n",
    "#k_top will be no. of features who are just retaining cumulative variance less than retain_variance\n",
    "k_top = len(var_eigen[var_eigen < (retain_variance * 100)])\n",
    "\n",
    "#final feature reduction\n",
    "X_feature_reduced_train = np.dot(U_train[:,:k_top].T,X_train.T)\n",
    "#X_feature_reduced_train = np.dot(U_test[:,:k_top].T,X_test.T)\n",
    "print (X_feature_reduced_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = neighbors.KNeighborsClassifier(5, weights='uniform')\n",
    "clf.fit(X_feature_reduced.T, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (clf.score(X_feature_reduced_train.T, Y_test),clf.score(X_feature_reduced_test.T, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
