{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import  matplotlib.image as mpimg\n",
    "\n",
    "from scipy import misc\n",
    "\n",
    "import argparse\n",
    "\n",
    "from PIL import Image \n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "#k is the training size\n",
    "k = int(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/shivam/Downloads/Face_Recog_PCA-master/dataset_ORL/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2vector(filename):\n",
    "\n",
    "    imgVector = np.array(Image.open(filename)).flatten()\n",
    "    return imgVector.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((160, 10304), (160,), (240, 10304), (240,))\n"
     ]
    }
   ],
   "source": [
    "train_X = []\n",
    "train_Y = []\n",
    "test_X = []\n",
    "test_Y  = []\n",
    "\n",
    "for i in range(1,41):\n",
    "    for j in range(1,k+1):\n",
    "        image_add = path+\"s\"+str(i)+\"/\"+str(j)+\".pgm\"\n",
    "        img = img2vector(image_add)\n",
    "        train_X.append(img)\n",
    "        train_Y.append(i)\n",
    "        \n",
    "    for j in range(k+1,11):\n",
    "        image_add = path+\"s\"+str(i)+\"/\"+str(j)+\".pgm\"\n",
    "        img = img2vector(image_add)\n",
    "        test_X.append(img)\n",
    "        test_Y.append(i)\n",
    "\n",
    "X_train = np.array(train_X)\n",
    "Y_train = np.array(train_Y)\n",
    "X_test = np.array(test_X)\n",
    "Y_test = np.array(test_Y)\n",
    "\n",
    "print (X_train.shape,Y_train.shape,X_test.shape,Y_test.shape)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10304)\n",
      "(160, 10304)\n"
     ]
    }
   ],
   "source": [
    "#normalize according to paper\n",
    "\n",
    "mean = X_train.mean(axis = 0).reshape(1,10304)\n",
    "\n",
    "print (mean.shape)\n",
    "\n",
    "X_train -= mean\n",
    "X_test -= mean\n",
    "\n",
    "print (X_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute covariance matrix\n",
    "cov_train = np.dot(X_train.T,X_train)\n",
    "cov_test = np.dot(X_test.T,X_test)\n",
    "cov_train /= X_train.shape[0]\n",
    "cov_test /= X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " computed eigen vectors and values of shape (10304, 10304)\n"
     ]
    }
   ],
   "source": [
    "#singular value decomposition for computing U : eigen vectors s : eigen values\n",
    "U_train, s_train, V_train = np.linalg.svd(cov_train, full_matrices = True)\n",
    "print (\" computed eigen vectors and values of shape {}\".format(U_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10304,)\n"
     ]
    }
   ],
   "source": [
    "print (s_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 160)\n"
     ]
    }
   ],
   "source": [
    "# approx retain variance\n",
    "retain_variance = 0.85\n",
    "sum of all eigen values\n",
    "eigen_value_sum = np.sum(s_train)\n",
    "var_eigen = np.array([(np.sum(s_train[: i + 1]) / eigen_value_sum) * 100.0 for i in range(s_train.shape[0])])\n",
    "\n",
    "#k_top will be no. of features who are just retaining cumulative variance less than retain_variance\n",
    "k_top = len(var_eigen[var_eigen < (retain_variance * 100)])\n",
    "\n",
    "#final feature reduction\n",
    "X_feature_reduced = np.dot(U_train[:,:k_top].T,X_train.T)\n",
    "print (X_feature_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
